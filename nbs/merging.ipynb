{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp merging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mesclagem\n",
    "> Funções auxiliares para mesclar e limpar as várias fontes de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from decimal import Decimal\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "from anateldb.constants import ENTIDADES\n",
    "from anateldb.format import input_coordenates, scrape_dataframe, df_optimize\n",
    "from anateldb.reading import read_icao, read_aisw, read_aisg, read_aero, read_base\n",
    "MAX_DIST = 0.5 #Km\n",
    "COLS = ['Frequency', 'Latitude', 'Longitude', 'Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aeronáutica\n",
    "Funções auxiliares para mesclar registros que são iguais das diversas bases da aeronáutica, i.e. estão a uma distância menor que `DIST` e verificar a validade da mesclagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def check_add_row(df, # DataFrame para mesclar adicionar o registro\n",
    "                  f, # Frequência (MHz) em análise do registro \n",
    "                  rows, # Lista de registros para mesclar\n",
    "                  dicts, # Dicionário fonte dos registros\n",
    "):\n",
    "    \"\"\"Mescla os registros em `rows` de frequência `f` e os adiciona como uma linha do DataFrame `df`\n",
    "    Os registros em `rows` somente são mesclados se ainda constarem nos dicionários fonte `dicts`\n",
    "    Após a mesclagem, os registros são removidos dos dicionários fonte `dicts`   \n",
    "    \"\"\"\n",
    "    if all(row.Index in dict for row, dict in zip(rows, dicts)):\n",
    "        lat = sum(row.Latitude for row in rows) / len(rows)\n",
    "        long = sum(row.Longitude for row in rows) / len(rows)\n",
    "        desc = ' | '.join(row.Description for row in rows)\n",
    "        d = {'Frequency': f, 'Latitude': lat, 'Longitude': long, 'Description': desc}\n",
    "        for row, dict in zip(rows, dicts):\n",
    "            dict.pop(row.Index)\n",
    "        return pd.concat([df, pd.DataFrame(d, index=[0])], ignore_index=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_subsets(f, # Frequência (MHz) em análise do registro\n",
    "                *dfs, # Conjunto de DataFrames a serem analisados\n",
    "):\n",
    "    \"\"\"Retorna os subconjuntos de registros de frequência `f` em cada dataframe `dfs`\n",
    "    Os subconjuntos são retornados em forma de dicionário, onde a chave é o índice do registro\n",
    "    \"\"\"\n",
    "    return [{s.Index: s for s in df.loc[df.Frequency == f, COLS].itertuples()} for df in dfs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def merge_closer(frequencies, # Lista de frequências em comum\n",
    "                 df, # DataFrame de saída\n",
    "                 df_left, # DataFrame 1 de entrada da esquerda\n",
    "                 df_right # DataFrame 2 de entrada da direita\n",
    "):\n",
    "    \"\"\"Mescla os registros de frequência `frequencies` de `df_left` e `df_right` em `df`\n",
    "    Essa função é utilizada para mesclar registros que possuem frequências em comum listadas em `frequencies`\n",
    "    Os registros são mesclados se a distância entre eles for menor que `MAX_DIST`\n",
    "    do contrário são adicionados individualmente como uma linha no DataFrame de saída `df`\t\n",
    "    \"\"\"\n",
    "    for f in frequencies:\n",
    "        sa, sb = get_subsets(f, df_left, df_right)\n",
    "        if all([sa, sb]): # Somente há registros para mesclar se estiverem nos dois conjuntos\n",
    "            for fa, fb in list(product(sa.copy().values(), sb.copy().values())):\n",
    "                if geodesic((fa.Latitude, fa.Longitude), (fb.Latitude, fb.Longitude)).km <= MAX_DIST:\n",
    "                    df = check_add_row(df, f, [fa, fb], [sa, sb]) \n",
    "        for reg in [sa, sb]: # Do contrário os registros são adicionados individualmente ao DataFrame\n",
    "            for r in reg.copy().values():\n",
    "                df = check_add_row(df, f, [r], [reg])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def merge_single(frequencies, # Lista de frequências em comum\n",
    "                 df, # DataFrame de saída\n",
    "                 df_left # DataFrame de entrada\n",
    "):\n",
    "    \"\"\"Mescla os registros de frequência `frequencies` de `df_left` em `df`\"\"\"\n",
    "    for f in frequencies:\n",
    "        if sa := get_subsets(f, df_left)[0]:\n",
    "            for fa in sa.copy().values():\n",
    "                df = check_add_row(df, f, [fa], [sa])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def merge_triple(frequencies, # Lista de frequências em comum\n",
    "                 df, # DataFrame de saída \n",
    "                 df_left, # DataFrame 1 de entrada\n",
    "                 df_middle, # DataFrame 2 de entrada \n",
    "                 df_right, # DataFrame 3 de entrada \n",
    "):\n",
    "    \"\"\"Mescla os registros de frequência `frequencies` de `df_left`, `df_middle` e `df_right` em `df`\n",
    "    Essa função é utilizada para mesclar registros que possuem frequências em comum listadas em `frequencies`\n",
    "    Os registros são mesclados se a distância entre eles for menor que `MAX_DIST`\n",
    "    do contrário são adicionados individualmente como uma linha no DataFrame de saída `df`\n",
    "    \"\"\"\n",
    "    for f in frequencies:\n",
    "        sa, sb, sc = get_subsets(f, df_left, df_middle, df_right)\n",
    "        if all([sa, sb, sc]):\n",
    "            for fa, fb, fc in list(product(sa.copy().values(), sb.copy().values(), sc.copy().values())):\n",
    "                dab = geodesic((fa.Latitude, fa.Longitude), (fb.Latitude, fb.Longitude)).km\n",
    "                dac = geodesic((fa.Latitude, fa.Longitude), (fc.Latitude, fc.Longitude)).km\n",
    "                dbc = geodesic((fb.Latitude, fb.Longitude), (fc.Latitude, fc.Longitude)).km\n",
    "                if all(d <= MAX_DIST  for d in [dab, dac, dbc]):\n",
    "                    df = check_add_row(df, f, [fa, fb, fc], [sa, sb, sc])\n",
    "                elif all(d > MAX_DIST  for d in [dac, dbc]):\n",
    "                    df = check_add_row(df, f, [fa, fb], [sa, sb])\n",
    "                elif all(d > MAX_DIST  for d in [dab, dac]):\n",
    "                    df = check_add_row(df, f, [fa, fc], [sb, sc])\n",
    "                elif all(d > MAX_DIST for d in [dab, dbc]):\n",
    "                    df = check_add_row(df, f, [fa, fc], [sa, sc])\n",
    "        for reg in [sa, sb, sc]:\n",
    "            for r in reg.copy().values():\n",
    "                df = check_add_row(df, f, [r], [reg])        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def check_merging(df, # DataFrame de saída\n",
    "                  icao, # DataFrame fonte 1\n",
    "                  aisw, # DataFrame fonte 2 \n",
    "                  aisg, # DataFrame fonte 3\n",
    "):\n",
    "    \"\"\"Verifica a validade da mesclagem dos registros de `icao`, `aisw` e `aisg` em `df`\"\"\"\n",
    "    three_merges = df[df.Description.str.contains('\\|.*\\|')]\n",
    "    two_merges = df[(df.Description.str.contains('[\\|]{1}')) & (~df.index.isin(three_merges.index))]\n",
    "    no_merge = df[~df.Description.str.contains('[\\|]{1}')]\n",
    "    return len(no_merge) + len(two_merges) * 2 + len(three_merges) * 3 == len(icao) + len(aisw) + len(aisg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_frequencies_set(df1, df2, df3):\n",
    "    \"\"\"Retorna todos os conjuntos de frequências do Diagrama de Venn entre os registros de `df1`, `df2` e `df3`\"\"\"\n",
    "    f1 = set(df1.Frequency.tolist())\n",
    "    f2 = set(df2.Frequency.tolist())\n",
    "    f3 = set(df3.Frequency.tolist())\n",
    "    ABC = f1.intersection(f2).intersection(f3)\n",
    "    AB = f1.intersection(f2).difference(ABC)\n",
    "    BC = f2.intersection(f3).difference(ABC)\n",
    "    AC = f1.intersection(f3).difference(ABC)\n",
    "    A = f1.difference(ABC).difference(AB).difference(AC)\n",
    "    B = f2.difference(ABC).difference(AB).difference(BC)\n",
    "    C = f3.difference(ABC).difference(BC).difference(AC)\n",
    "    return A, B, C, AB, AC, BC, ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def merge_aero(folder, # Pasta onde estão os arquivos de entrada\n",
    "):\n",
    "    \"\"\"Mescla os registros de mesma frequência e próximos dos arquivos da aeronáutica em `folder`\"\"\"\n",
    "    icao = read_icao(folder).drop(columns=['Service', 'Station'])\n",
    "    aisw = read_aisw(folder).drop(columns=['Service', 'Station'])\n",
    "    aisg = read_aisg(folder).drop(columns=['Service', 'Station'])\n",
    "    df = pd.DataFrame(columns=['Frequency', 'Latitude', 'Longitude', 'Description'])\n",
    "    A, B, C, AB, AC, BC, ABC = get_frequencies_set(icao, aisw, aisg)\n",
    "    df = merge_closer(AB, df, icao, aisw)\n",
    "    df = merge_closer(AC, df, icao, aisg)\n",
    "    df = merge_closer(BC, df, aisw, aisg)\n",
    "    df = merge_single(A, df, icao)\n",
    "    df = merge_single(B, df, aisw)\n",
    "    df = merge_single(C, df, aisg)\n",
    "    df = merge_triple(ABC, df, icao, aisw, aisg)\n",
    "    if not check_merging(df, icao, aisw, aisg):\n",
    "        raise ValueError(\"Divergência na contagem de linhas entre as bases individuais e a combinação\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo : False\n",
    "def _merge_dfs(df1, df2, on, how=\"left\"):\n",
    "    \"\"\"Merge two dataframes with the same columns and records\"\"\"\n",
    "    df = pd.merge(df1, df2, on=on, how=how)\n",
    "    x = df.Description_x.notna()\n",
    "    y = df.Description_y.notna()\n",
    "    df.loc[x & y, \"Description\"] = (\n",
    "        df.loc[x & y, \"Description_x\"] + \" | \" + df.loc[x & y, \"Description_y\"]\n",
    "    )\n",
    "    df.loc[x & ~y, \"Description\"] = df.loc[x & ~y, \"Description_x\"]\n",
    "    df.loc[~x & y, \"Description\"] = df.loc[~x & y, \"Description_y\"]\n",
    "    df.loc[x & y, \"Latitude\"] = (\n",
    "        df.loc[x & y, \"Latitude_x\"] + df.loc[x & y, \"Latitude_y\"]\n",
    "    ) / 2\n",
    "    df.loc[x & y, \"Longitude\"] = (\n",
    "        df.loc[x & y, \"Longitude_x\"] + df.loc[x & y, \"Longitude_y\"]\n",
    "    ) / 2\n",
    "    df.loc[x & ~y, \"Latitude\"] = df.loc[x & ~y, \"Latitude_x\"]\n",
    "    df.loc[x & ~y, \"Longitude\"] = df.loc[x & ~y, \"Longitude_x\"]\n",
    "    df.loc[~x & y, \"Latitude\"] = df.loc[~x & y, \"Latitude_y\"]\n",
    "    df.loc[~x & y, \"Longitude\"] = df.loc[~x & y, \"Longitude_y\"]\n",
    "    if \"Service_x\" in df.columns and \"Service_y\" in df.columns:\n",
    "        df.loc[x, \"Service\"] = df.loc[x, \"Service_x\"]\n",
    "        df.loc[~x & y, \"Service\"] = df.loc[~x & y, \"Service_y\"]\n",
    "    return df.loc[:, [c for c in df.columns if \"_\" not in c]]\n",
    "\n",
    "\n",
    "def aero_common(dfa, dfb, dfc):\n",
    "    cols = [\"Frequency\", \"Station\"]\n",
    "    a = dfa[dfa.Station != -1].reset_index(drop=True)\n",
    "    b = dfb[dfb.Station != -1].reset_index(drop=True)\n",
    "    c = dfc[dfc.Station != -1].reset_index(drop=True)\n",
    "    common = _merge_dfs(a, b, cols, how=\"outer\")\n",
    "    common = _merge_dfs(common, c, cols, how=\"outer\")\n",
    "    common.drop_duplicates(inplace=True, keep=\"first\")\n",
    "    return common.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo : False\n",
    "def aero_new(dfa, dfb, dfc, dist=500):\n",
    "    cols = [\"Frequency\"]\n",
    "    a = (\n",
    "        dfa[dfa.Station == -1]\n",
    "        .drop(columns=[\"Service\", \"Station\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    b = (\n",
    "        dfb[dfb.Station == -1]\n",
    "        .drop(columns=[\"Service\", \"Station\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    c = (\n",
    "        dfc[dfc.Station == -1]\n",
    "        .drop(columns=[\"Service\", \"Station\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    abc = (\n",
    "        pd.merge(a, b, on=cols, how=\"outer\")\n",
    "        .merge(c, on=cols, how=\"outer\")\n",
    "        .reset_index(drop=True)\n",
    "        .drop_duplicates(keep=\"first\")\n",
    "    )\n",
    "    x = abc.Description_x.notna()\n",
    "    y = abc.Description_y.notna()\n",
    "    z = abc.Description.notna()\n",
    "    new = pd.DataFrame(columns=[\"Frequency\", \"Latitude\", \"Longitude\", \"Description\"])\n",
    "\n",
    "    for c, n in zip([(x & ~y & ~z), (~x & y & ~z), (~x & ~y & z)], [\"_x\", \"_y\", \"\"]):\n",
    "        temp = abc.loc[\n",
    "            c, [\"Frequency\", f\"Latitude{n}\", f\"Longitude{n}\", f\"Description{n}\"]\n",
    "        ]\n",
    "        temp.columns = [\"Frequency\", \"Latitude\", \"Longitude\", \"Description\"]\n",
    "        new = pd.concat([new, temp], ignore_index=True)\n",
    "\n",
    "    new = new.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "    for c, (left, right) in zip(\n",
    "        [(x & y & ~z), (x & ~y & z), (~x & y & z)],\n",
    "        [(\"_x\", \"_y\"), (\"_x\", \"\"), (\"_y\", \"\")],\n",
    "    ):\n",
    "        for row in abc[c].itertuples():\n",
    "            d = geodesic(\n",
    "                (getattr(row, f\"Latitude{left}\"), getattr(row, f\"Longitude{left}\")),\n",
    "                (getattr(row, f\"Latitude{right}\"), getattr(row, f\"Longitude{right}\")),\n",
    "            ).m\n",
    "            if d < dist:\n",
    "                f = row.Frequency\n",
    "                lat = (\n",
    "                    getattr(row, f\"Latitude{left}\") + getattr(row, f\"Latitude{right}\")\n",
    "                ) / 2\n",
    "                lon = (\n",
    "                    getattr(row, f\"Longitude{left}\") + getattr(row, f\"Longitude{right}\")\n",
    "                ) / 2\n",
    "                d = (\n",
    "                    getattr(row, f\"Description{left}\")\n",
    "                    + \" | \"\n",
    "                    + getattr(row, f\"Description{right}\")\n",
    "                )\n",
    "                new = pd.concat(\n",
    "                    [\n",
    "                        new,\n",
    "                        pd.DataFrame(\n",
    "                            [[f, lat, lon, d]],\n",
    "                            columns=[\n",
    "                                \"Frequency\",\n",
    "                                \"Latitude\",\n",
    "                                \"Longitude\",\n",
    "                                \"Description\",\n",
    "                            ],\n",
    "                        ),\n",
    "                    ],\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "            else:\n",
    "                l = (\n",
    "                    abc.loc[\n",
    "                        row.Index,\n",
    "                        [\n",
    "                            \"Frequency\",\n",
    "                            f\"Latitude{left}\",\n",
    "                            f\"Longitude{left}\",\n",
    "                            f\"Description{left}\",\n",
    "                        ],\n",
    "                    ]\n",
    "                    .to_frame()\n",
    "                    .T\n",
    "                )\n",
    "                l.columns = new.columns\n",
    "                r = (\n",
    "                    abc.loc[\n",
    "                        row.Index,\n",
    "                        [\n",
    "                            \"Frequency\",\n",
    "                            f\"Latitude{right}\",\n",
    "                            f\"Longitude{right}\",\n",
    "                            f\"Description{right}\",\n",
    "                        ],\n",
    "                    ]\n",
    "                    .to_frame()\n",
    "                    .T\n",
    "                )\n",
    "                r.columns = new.columns\n",
    "                new = pd.concat([new, l, r], ignore_index=True)\n",
    "\n",
    "    new = new.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "    for row in abc[x & y & z].itertuples():\n",
    "        d1 = geodesic(\n",
    "            (getattr(row, \"Latitude_x\"), getattr(row, \"Longitude_x\")),\n",
    "            (getattr(row, \"Latitude_y\"), getattr(row, \"Longitude_y\")),\n",
    "        ).m\n",
    "        d2 = geodesic(\n",
    "            (getattr(row, \"Latitude_x\"), getattr(row, \"Longitude_x\")),\n",
    "            (getattr(row, \"Latitude\"), getattr(row, \"Longitude\")),\n",
    "        ).m\n",
    "        d3 = geodesic(\n",
    "            (getattr(row, \"Latitude_y\"), getattr(row, \"Longitude_y\")),\n",
    "            (getattr(row, \"Latitude\"), getattr(row, \"Longitude\")),\n",
    "        ).m\n",
    "        if d1 < dist and d2 < dist and d3 < dist:\n",
    "            f = row.Frequency\n",
    "            lat = (row.Latitude_x + row.Latitude_y + row.Latitude) / 3\n",
    "            lon = (row.Longitude_x + row.Longitude_y + row.Longitude) / 3\n",
    "            d = \" | \".join([row.Description_x, row.Description_y, row.Description])\n",
    "            new = pd.concat(\n",
    "                [\n",
    "                    new,\n",
    "                    pd.DataFrame(\n",
    "                        [[f, lat, lon, d]],\n",
    "                        columns=[\"Frequency\", \"Latitude\", \"Longitude\", \"Description\"],\n",
    "                    ),\n",
    "                ],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "        elif d1 < dist and d2 < dist:\n",
    "            f = row.Frequency\n",
    "            lat = (row.Latitude_x + row.Latitude_y) / 2\n",
    "            lon = (row.Longitude_x + row.Longitude_y) / 2\n",
    "            d = \" | \".join([row.Description_x, row.Description_y])\n",
    "            new = pd.concat(\n",
    "                [\n",
    "                    new,\n",
    "                    pd.DataFrame(\n",
    "                        [[f, lat, lon, d]],\n",
    "                        columns=[\"Frequency\", \"Latitude\", \"Longitude\", \"Description\"],\n",
    "                    ),\n",
    "                ],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "        elif d1 < dist and d3 < dist:\n",
    "            f = row.Frequency\n",
    "            lat = (row.Latitude_x + row.Latitude) / 2\n",
    "            lon = (row.Longitude_x + row.Longitude) / 2\n",
    "            d = \" | \".join([row.Description_x, row.Description])\n",
    "            new = pd.concat(\n",
    "                [\n",
    "                    new,\n",
    "                    pd.DataFrame(\n",
    "                        [[f, lat, lon, d]],\n",
    "                        columns=[\"Frequency\", \"Latitude\", \"Longitude\", \"Description\"],\n",
    "                    ),\n",
    "                ],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "        elif d2 < dist and d3 < dist:\n",
    "            f = row.Frequency\n",
    "            lat = (row.Latitude_y + row.Latitude) / 2\n",
    "            lon = (row.Longitude_y + row.Longitude) / 2\n",
    "            d = \" | \".join([row.Description_y, row.Description])\n",
    "            new = pd.concat(\n",
    "                [\n",
    "                    new,\n",
    "                    pd.DataFrame(\n",
    "                        [[f, lat, lon, d]],\n",
    "                        columns=[\"Frequency\", \"Latitude\", \"Longitude\", \"Description\"],\n",
    "                    ),\n",
    "                ],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "        else:\n",
    "            l = (\n",
    "                abc.loc[\n",
    "                    row.Index,\n",
    "                    [\"Frequency\", \"Latitude_x\", \"Longitude_x\", \"Description_x\"],\n",
    "                ]\n",
    "                .to_frame()\n",
    "                .T\n",
    "            )\n",
    "            l.columns = new.columns\n",
    "            r = (\n",
    "                abc.loc[\n",
    "                    row.Index,\n",
    "                    [\"Frequency\", \"Latitude_y\", \"Longitude_y\", \"Description_y\"],\n",
    "                ]\n",
    "                .to_frame()\n",
    "                .T\n",
    "            )\n",
    "            r.columns = new.columns\n",
    "            s = (\n",
    "                abc.loc[\n",
    "                    row.Index, [\"Frequency\", \"Latitude\", \"Longitude\", \"Description\"]\n",
    "                ]\n",
    "                .to_frame()\n",
    "                .T\n",
    "            )\n",
    "            s.columns = new.columns\n",
    "            new = pd.concat([new, l, r, s], ignore_index=True)\n",
    "\n",
    "    new = new.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "    new[\"Service\"] = pd.NA\n",
    "    new[\"Station\"] = pd.NA\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo : False\n",
    "\n",
    "def merge_aero(df, common, new):\n",
    "    \"\"\"Mescla a base da Anatel com as tabelas retiradas da Aeronáutica\"\"\"\n",
    "    common = common.loc[:, [\"Frequency\", \"Description\", \"Service\", \"Station\"]]\n",
    "    df[\"Description\"] = df.Description.astype(\"string\")\n",
    "    df = pd.merge(df, common, on=[\"Frequency\", \"Service\", \"Station\"], how=\"left\")\n",
    "    df.loc[df.Description_y.notna(), \"Description_x\"] = (\n",
    "        df.loc[df.Description_y.notna(), \"Description_x\"]\n",
    "        + \" | \"\n",
    "        + df.loc[df.Description_y.notna(), \"Description_y\"]\n",
    "    )\n",
    "    df.drop(columns=[\"Description_y\"], inplace=True)\n",
    "    df.rename(columns={\"Description_x\": \"Description\"}, inplace=True)\n",
    "    new['Class'] = pd.NA\n",
    "    new['BW'] = pd.NA\n",
    "    return (\n",
    "        pd.concat([df, new], ignore_index=True)\n",
    "        .sort_values(\"Frequency\")\n",
    "        .reset_index(drop=True)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('anateldb')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
