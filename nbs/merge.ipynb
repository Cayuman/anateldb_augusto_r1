{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T19:42:17.354806Z",
     "start_time": "2022-07-08T19:42:17.230470Z"
    }
   },
   "outputs": [],
   "source": [
    "#default_exp merge\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T19:42:17.449058Z",
     "start_time": "2022-07-08T19:42:17.357802Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge\n",
    "> Utility functions to correcly merge and clean the various data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T19:42:24.145461Z",
     "start_time": "2022-07-08T19:42:17.451084Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from decimal import Decimal\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "from anateldb.constants import ENTIDADES\n",
    "from anateldb.format import input_coordenates, scrape_dataframe, df_optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T19:42:24.334960Z",
     "start_time": "2022-07-08T19:42:24.147457Z"
    }
   },
   "outputs": [],
   "source": [
    "#export \n",
    "def _merge_dfs(df1, df2, on, how=\"left\"):\n",
    "    \"\"\"Merge two dataframes with the same columns and records\"\"\"\n",
    "    df = pd.merge(df1, df2, on=on, how=how)\n",
    "    x = df.Description_x.notna()\n",
    "    y = df.Description_y.notna()\n",
    "    df.loc[x & y, \"Description\"] = (\n",
    "        df.loc[x & y, \"Description_x\"] + \" | \" + df.loc[x & y, \"Description_y\"]\n",
    "    )\n",
    "    df.loc[x & ~y, \"Description\"] = df.loc[x & ~y, \"Description_x\"]\n",
    "    df.loc[~x & y, \"Description\"] = df.loc[~x & y, \"Description_y\"]\n",
    "    df.loc[x & y, \"Latitude\"] = (\n",
    "        df.loc[x & y, \"Latitude_x\"] + df.loc[x & y, \"Latitude_y\"]\n",
    "    ) / 2\n",
    "    df.loc[x & y, \"Longitude\"] = (\n",
    "        df.loc[x & y, \"Longitude_x\"] + df.loc[x & y, \"Longitude_y\"]\n",
    "    ) / 2\n",
    "    df.loc[x & ~y, \"Latitude\"] = df.loc[x & ~y, \"Latitude_x\"]\n",
    "    df.loc[x & ~y, \"Longitude\"] = df.loc[x & ~y, \"Longitude_x\"]\n",
    "    df.loc[~x & y, \"Latitude\"] = df.loc[~x & y, \"Latitude_y\"]\n",
    "    df.loc[~x & y, \"Longitude\"] = df.loc[~x & y, \"Longitude_y\"]\n",
    "    if \"Service_x\" in df.columns and \"Service_y\" in df.columns:\n",
    "        df.loc[x, \"Service\"] = df.loc[x, \"Service_x\"]\n",
    "        df.loc[~x & y, \"Service\"] = df.loc[~x & y, \"Service_y\"]\n",
    "    return df.loc[:, [c for c in df.columns if \"_\" not in c]]\n",
    "\n",
    "\n",
    "def aero_common(dfa, dfb, dfc):\n",
    "    cols = [\"Frequency\", \"Station\"]\n",
    "    a = dfa[dfa.Station != -1].reset_index(drop=True)\n",
    "    b = dfb[dfb.Station != -1].reset_index(drop=True)\n",
    "    c = dfc[dfc.Station != -1].reset_index(drop=True)\n",
    "    common = _merge_dfs(a, b, cols, how=\"outer\")\n",
    "    common = _merge_dfs(common, c, cols, how=\"outer\")\n",
    "    common.drop_duplicates(inplace=True, keep=\"first\")\n",
    "    return common.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T19:42:24.542196Z",
     "start_time": "2022-07-08T19:42:24.340945Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def aero_new(dfa, dfb, dfc, dist=500):\n",
    "    cols = [\"Frequency\"]\n",
    "    a = (\n",
    "        dfa[dfa.Station == -1]\n",
    "        .drop(columns=[\"Service\", \"Station\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    b = (\n",
    "        dfb[dfb.Station == -1]\n",
    "        .drop(columns=[\"Service\", \"Station\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    c = (\n",
    "        dfc[dfc.Station == -1]\n",
    "        .drop(columns=[\"Service\", \"Station\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    abc = (\n",
    "        pd.merge(a, b, on=cols, how=\"outer\")\n",
    "        .merge(c, on=cols, how=\"outer\")\n",
    "        .reset_index(drop=True)\n",
    "        .drop_duplicates(keep=\"first\")\n",
    "    )\n",
    "    x = abc.Description_x.notna()\n",
    "    y = abc.Description_y.notna()\n",
    "    z = abc.Description.notna()\n",
    "    new = pd.DataFrame(columns=[\"Frequency\", \"Latitude\", \"Longitude\", \"Description\"])\n",
    "\n",
    "    for c, n in zip([(x & ~y & ~z), (~x & y & ~z), (~x & ~y & z)], [\"_x\", \"_y\", \"\"]):\n",
    "        temp = abc.loc[\n",
    "            c, [\"Frequency\", f\"Latitude{n}\", f\"Longitude{n}\", f\"Description{n}\"]\n",
    "        ]\n",
    "        temp.columns = [\"Frequency\", \"Latitude\", \"Longitude\", \"Description\"]\n",
    "        new = pd.concat([new, temp], ignore_index=True)\n",
    "\n",
    "    new = new.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "    for c, (left, right) in zip(\n",
    "        [(x & y & ~z), (x & ~y & z), (~x & y & z)],\n",
    "        [(\"_x\", \"_y\"), (\"_x\", \"\"), (\"_y\", \"\")],\n",
    "    ):\n",
    "        for row in abc[c].itertuples():\n",
    "            d = geodesic(\n",
    "                (getattr(row, f\"Latitude{left}\"), getattr(row, f\"Longitude{left}\")),\n",
    "                (getattr(row, f\"Latitude{right}\"), getattr(row, f\"Longitude{right}\")),\n",
    "            ).m\n",
    "            if d < dist:\n",
    "                f = row.Frequency\n",
    "                lat = (\n",
    "                    getattr(row, f\"Latitude{left}\") + getattr(row, f\"Latitude{right}\")\n",
    "                ) / 2\n",
    "                lon = (\n",
    "                    getattr(row, f\"Longitude{left}\") + getattr(row, f\"Longitude{right}\")\n",
    "                ) / 2\n",
    "                d = (\n",
    "                    getattr(row, f\"Description{left}\")\n",
    "                    + \" | \"\n",
    "                    + getattr(row, f\"Description{right}\")\n",
    "                )\n",
    "                new = pd.concat(\n",
    "                    [\n",
    "                        new,\n",
    "                        pd.DataFrame(\n",
    "                            [[f, lat, lon, d]],\n",
    "                            columns=[\n",
    "                                \"Frequency\",\n",
    "                                \"Latitude\",\n",
    "                                \"Longitude\",\n",
    "                                \"Description\",\n",
    "                            ],\n",
    "                        ),\n",
    "                    ],\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "            else:\n",
    "                l = (\n",
    "                    abc.loc[\n",
    "                        row.Index,\n",
    "                        [\n",
    "                            \"Frequency\",\n",
    "                            f\"Latitude{left}\",\n",
    "                            f\"Longitude{left}\",\n",
    "                            f\"Description{left}\",\n",
    "                        ],\n",
    "                    ]\n",
    "                    .to_frame()\n",
    "                    .T\n",
    "                )\n",
    "                l.columns = new.columns\n",
    "                r = (\n",
    "                    abc.loc[\n",
    "                        row.Index,\n",
    "                        [\n",
    "                            \"Frequency\",\n",
    "                            f\"Latitude{right}\",\n",
    "                            f\"Longitude{right}\",\n",
    "                            f\"Description{right}\",\n",
    "                        ],\n",
    "                    ]\n",
    "                    .to_frame()\n",
    "                    .T\n",
    "                )\n",
    "                r.columns = new.columns\n",
    "                new = pd.concat([new, l, r], ignore_index=True)\n",
    "\n",
    "    new = new.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "    for row in abc[x & y & z].itertuples():\n",
    "        d1 = geodesic(\n",
    "            (getattr(row, \"Latitude_x\"), getattr(row, \"Longitude_x\")),\n",
    "            (getattr(row, \"Latitude_y\"), getattr(row, \"Longitude_y\")),\n",
    "        ).m\n",
    "        d2 = geodesic(\n",
    "            (getattr(row, \"Latitude_x\"), getattr(row, \"Longitude_x\")),\n",
    "            (getattr(row, \"Latitude\"), getattr(row, \"Longitude\")),\n",
    "        ).m\n",
    "        d3 = geodesic(\n",
    "            (getattr(row, \"Latitude_y\"), getattr(row, \"Longitude_y\")),\n",
    "            (getattr(row, \"Latitude\"), getattr(row, \"Longitude\")),\n",
    "        ).m\n",
    "        if d1 < dist and d2 < dist and d3 < dist:\n",
    "            f = row.Frequency\n",
    "            lat = (row.Latitude_x + row.Latitude_y + row.Latitude) / 3\n",
    "            lon = (row.Longitude_x + row.Longitude_y + row.Longitude) / 3\n",
    "            d = \" | \".join([row.Description_x, row.Description_y, row.Description])\n",
    "            new = pd.concat(\n",
    "                [\n",
    "                    new,\n",
    "                    pd.DataFrame(\n",
    "                        [[f, lat, lon, d]],\n",
    "                        columns=[\"Frequency\", \"Latitude\", \"Longitude\", \"Description\"],\n",
    "                    ),\n",
    "                ],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "        elif d1 < dist and d2 < dist:\n",
    "            f = row.Frequency\n",
    "            lat = (row.Latitude_x + row.Latitude_y) / 2\n",
    "            lon = (row.Longitude_x + row.Longitude_y) / 2\n",
    "            d = \" | \".join([row.Description_x, row.Description_y])\n",
    "            new = pd.concat(\n",
    "                [\n",
    "                    new,\n",
    "                    pd.DataFrame(\n",
    "                        [[f, lat, lon, d]],\n",
    "                        columns=[\"Frequency\", \"Latitude\", \"Longitude\", \"Description\"],\n",
    "                    ),\n",
    "                ],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "        elif d1 < dist and d3 < dist:\n",
    "            f = row.Frequency\n",
    "            lat = (row.Latitude_x + row.Latitude) / 2\n",
    "            lon = (row.Longitude_x + row.Longitude) / 2\n",
    "            d = \" | \".join([row.Description_x, row.Description])\n",
    "            new = pd.concat(\n",
    "                [\n",
    "                    new,\n",
    "                    pd.DataFrame(\n",
    "                        [[f, lat, lon, d]],\n",
    "                        columns=[\"Frequency\", \"Latitude\", \"Longitude\", \"Description\"],\n",
    "                    ),\n",
    "                ],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "        elif d2 < dist and d3 < dist:\n",
    "            f = row.Frequency\n",
    "            lat = (row.Latitude_y + row.Latitude) / 2\n",
    "            lon = (row.Longitude_y + row.Longitude) / 2\n",
    "            d = \" | \".join([row.Description_y, row.Description])\n",
    "            new = pd.concat(\n",
    "                [\n",
    "                    new,\n",
    "                    pd.DataFrame(\n",
    "                        [[f, lat, lon, d]],\n",
    "                        columns=[\"Frequency\", \"Latitude\", \"Longitude\", \"Description\"],\n",
    "                    ),\n",
    "                ],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "        else:\n",
    "            l = (\n",
    "                abc.loc[\n",
    "                    row.Index,\n",
    "                    [\"Frequency\", \"Latitude_x\", \"Longitude_x\", \"Description_x\"],\n",
    "                ]\n",
    "                .to_frame()\n",
    "                .T\n",
    "            )\n",
    "            l.columns = new.columns\n",
    "            r = (\n",
    "                abc.loc[\n",
    "                    row.Index,\n",
    "                    [\"Frequency\", \"Latitude_y\", \"Longitude_y\", \"Description_y\"],\n",
    "                ]\n",
    "                .to_frame()\n",
    "                .T\n",
    "            )\n",
    "            r.columns = new.columns\n",
    "            s = (\n",
    "                abc.loc[\n",
    "                    row.Index, [\"Frequency\", \"Latitude\", \"Longitude\", \"Description\"]\n",
    "                ]\n",
    "                .to_frame()\n",
    "                .T\n",
    "            )\n",
    "            s.columns = new.columns\n",
    "            new = pd.concat([new, l, r, s], ignore_index=True)\n",
    "\n",
    "    new = new.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "    new[\"Service\"] = pd.NA\n",
    "    new[\"Station\"] = pd.NA\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T19:42:24.732687Z",
     "start_time": "2022-07-08T19:42:24.544191Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def merge_aero(df, common, new):\n",
    "    \"\"\"Mescla a base da Anatel com as tabelas retiradas da Aeronáutica\"\"\"\n",
    "    common = common.loc[:, [\"Frequency\", \"Description\", \"Service\", \"Station\"]]\n",
    "    df[\"Description\"] = df.Description.astype(\"string\")\n",
    "    df = pd.merge(df, common, on=[\"Frequency\", \"Service\", \"Station\"], how=\"left\")\n",
    "    df.loc[df.Description_y.notna(), \"Description_x\"] = (\n",
    "        df.loc[df.Description_y.notna(), \"Description_x\"]\n",
    "        + \" | \"\n",
    "        + df.loc[df.Description_y.notna(), \"Description_y\"]\n",
    "    )\n",
    "    df.drop(columns=[\"Description_y\"], inplace=True)\n",
    "    df.rename(columns={\"Description_x\": \"Description\"}, inplace=True)\n",
    "    new['Class'] = pd.NA\n",
    "    new['BW'] = pd.NA\n",
    "    return (\n",
    "        pd.concat([df, new], ignore_index=True)\n",
    "        .sort_values(\"Frequency\")\n",
    "        .reset_index(drop=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T19:42:24.923178Z",
     "start_time": "2022-07-08T19:42:24.735680Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def clean_mosaico(df, pasta):\n",
    "    \"\"\"Clean the merged dataframe with the data from the MOSAICO page\"\"\"\n",
    "    COLS = [c for c in df.columns if \"_x\" in c]\n",
    "    for col in COLS:\n",
    "        col_x = col\n",
    "        col_y = col.split(\"_\")[0] + \"_y\"\n",
    "        df.loc[df[col_x].isna(), col_x] = df.loc[df[col_x].isna(), col_y]\n",
    "        df.loc[df[col_y].isna(), col_y] = df.loc[df[col_y].isna(), col_x]\n",
    "        if df[col_x].notna().sum() > df[col_y].notna().sum():\n",
    "            a, b = col_x, col_y\n",
    "        else:\n",
    "            a, b = col_y, col_x\n",
    "        df.drop(b, axis=1, inplace=True)\n",
    "        df.rename({a: a[:-2]}, axis=1, inplace=True)\n",
    "\n",
    "    df.loc[df.Latitude_Transmissor == \"\", \"Latitude_Transmissor\"] = df.loc[\n",
    "        df.Latitude_Transmissor == \"\", \"Latitude_Estação\"\n",
    "    ]\n",
    "    df.loc[df.Longitude_Transmissor == \"\", \"Longitude_Transmissor\"] = df.loc[\n",
    "        df.Longitude_Transmissor == \"\", \"Longitude_Estação\"\n",
    "    ]\n",
    "    df.loc[df.Latitude_Transmissor.isna(), \"Latitude_Transmissor\"] = df.loc[\n",
    "        df.Latitude_Transmissor.isna(), \"Latitude_Estação\"\n",
    "    ]\n",
    "    df.loc[df.Longitude_Transmissor.isna(), \"Longitude_Transmissor\"] = df.loc[\n",
    "        df.Longitude_Transmissor.isna(), \"Longitude_Estação\"\n",
    "    ]\n",
    "    df.drop([\"Latitude_Estação\", \"Longitude_Estação\"], axis=1, inplace=True)\n",
    "    df.rename(\n",
    "        columns={\n",
    "            \"Latitude_Transmissor\": \"Latitude\",\n",
    "            \"Longitude_Transmissor\": \"Longitude\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    df = input_coordenates(df, pasta)\n",
    "    df.loc[:, \"Frequência\"] = df.Frequência.str.replace(\",\", \".\")\n",
    "    if freq_nans := df[df.Frequência.isna()].Id.tolist():\n",
    "        complement_df = scrape_dataframe(freq_nans)\n",
    "        df.loc[\n",
    "            df.Frequência.isna(),\n",
    "            [\n",
    "                \"Status\",\n",
    "                \"Entidade\",\n",
    "                \"Fistel\",\n",
    "                \"Frequência\",\n",
    "                \"Classe\",\n",
    "                \"Num_Serviço\",\n",
    "                \"Município\",\n",
    "                \"UF\",\n",
    "            ],\n",
    "        ] = complement_df.values\n",
    "\n",
    "    df.loc[:, \"Frequência\"] = df.Frequência.astype(\"float\")\n",
    "    df.loc[df.Serviço == \"OM\", \"Frequência\"] = df.loc[\n",
    "        df.Serviço == \"OM\", \"Frequência\"\n",
    "    ].apply(lambda x: Decimal(x) / Decimal(1000))\n",
    "    df.loc[:, \"Validade_RF\"] = df.Validade_RF.astype(\"string\").str.slice(0, 10)\n",
    "    return df.drop_duplicates(keep=\"first\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-08T19:42:28.239887Z",
     "start_time": "2022-07-08T19:42:24.926170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted constants.ipynb.\n",
      "Converted filter.ipynb.\n",
      "Converted format.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted merge.ipynb.\n",
      "Converted query.ipynb.\n",
      "Converted read.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('db')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "737b3e0e8750f89ce31674571febe5a5a08e902b32bb8cbee589bdf91ca77e61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
