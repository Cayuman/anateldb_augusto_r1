{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp query\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries\n",
    "\n",
    "> Este módulo executa as queries sql / MongoDB necessárias para baixar os dados do STEL, RADCOM e MOSAICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decimal import *\n",
    "from typing import *\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from fastcore.test import *\n",
    "from rich.console import Console\n",
    "from pyarrow import ArrowInvalid\n",
    "from geopy.distance import geodesic\n",
    "import pandas_read_xml as pdx\n",
    "from unidecode import unidecode\n",
    "from fastcore.foundation import L\n",
    "from fastcore.utils import listify\n",
    "\n",
    "\n",
    "from anateldb.constants import *\n",
    "from anateldb.format import df_optimize, parse_bw, dict2cols\n",
    "from anateldb.merge import clean_mosaico\n",
    "\n",
    "getcontext().prec = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conexão com o banco de dados\n",
    "A função a seguir é um `wrapper` simples que utiliza o `pyodbc` para se conectar ao banco de dados base da Anatel e retorna o objeto da conexão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def connect_db():\n",
    "    \"\"\"Conecta ao Banco ANATELBDRO01 e retorna o 'cursor' (iterador) do Banco pronto para fazer iterações\"\"\"\n",
    "    return pyodbc.connect(\n",
    "        \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "        \"Server=ANATELBDRO01;\"\n",
    "        \"Database=SITARWEB;\"\n",
    "        \"Trusted_Connection=yes;\"\n",
    "        \"MultipleActiveResultSets=True;\",\n",
    "        timeout=TIMEOUT,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "def test_connection():\n",
    "    conn = connect_db()\n",
    "    cursor = conn.cursor()\n",
    "    for query in (RADCOM, STEL):\n",
    "        cursor.execute(query)\n",
    "        test_eq(type(cursor.fetchone()), pyodbc.Row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _read_estações(path: Union[str, Path])->pd.DataFrame:\n",
    "    \"\"\"Read the zipped xml file `Estações.zip` from MOSAICO and returns a dataframe\"\"\"\n",
    "    def extrair_ato(row):\n",
    "        if not isinstance(row, str):\n",
    "            row = listify(row)[::-1]\n",
    "            for d in row:\n",
    "                if not isinstance(d, dict):\n",
    "                    continue\n",
    "                if (d.get(\"@TipoDocumento\") == \"Ato\") and (\n",
    "                    d.get(\"@Razao\") == \"Autoriza o Uso de Radiofrequência\"\n",
    "                ):\n",
    "                    return d[\"@NumDocumento\"], d[\"@DataDOU\"][:10]\n",
    "            return \"\", \"\"\n",
    "        return \"\", \"\"\n",
    "\n",
    "    es = pdx.read_xml(path, [\"estacao_rd\"])\n",
    "    dfs = []\n",
    "    for i in range(es.shape[0]):\n",
    "        df = pd.DataFrame(es[\"row\"][i]).replace(\"\", pd.NA)\n",
    "        df = dict2cols(df)\n",
    "        df.columns = [unidecode(c).lower().replace(\"@\", \"\") for c in df.columns]\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs)\n",
    "    df = df[df.state.str.contains(\"-C1$|-C2$|-C3$|-C4$|-C7|-C98$\")].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    docs = L(df.historico_documentos.apply(extrair_ato).tolist())\n",
    "    df = df.loc[:, COL_ESTACOES]\n",
    "    df[\"Num_Ato\"] = docs.itemgot(0).map(str)\n",
    "    df[\"Data_Ato\"] = docs.itemgot(1).map(str)\n",
    "    df.columns = NEW_ESTACOES\n",
    "    df[\"Validade_RF\"] = df.Validade_RF.astype(\"string\").str.slice(0, 10)\n",
    "    df[\"Data_Ato\"] = df.Data_Ato.str.slice(0, 10)\n",
    "    for c in df.columns:\n",
    "        df.loc[df[c] == \"\", c] = pd.NA\n",
    "    return df\n",
    "\n",
    "\n",
    "def _read_plano_basico(path: Union[str, Path])->pd.DataFrame:\n",
    "    \"\"\"Read the zipped xml file `Plano_Básico.zip` from MOSAICO and returns a dataframe\"\"\"\n",
    "    pb = pdx.read_xml(path, [\"plano_basico\"])\n",
    "    dfs = []\n",
    "    for i in range(pb.shape[0]):\n",
    "        df = pd.DataFrame(pb[\"row\"][i]).replace(\"\", pd.NA)\n",
    "        df = dict2cols(df)\n",
    "        df.columns = [unidecode(c).lower().replace(\"@\", \"\") for c in df.columns]\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs)\n",
    "    df = df.loc[df.pais == \"BRA\", COL_PB].reset_index(drop=True)\n",
    "    for c in df.columns:\n",
    "        df.loc[df[c] == \"\", c] = pd.NA\n",
    "    df.columns = NEW_PB\n",
    "    df.sort_values([\"Id\", \"Canal\"], inplace=True)\n",
    "    ENTIDADES.update(\n",
    "        {r.Fistel: r.Entidade for r in df.itertuples() if str(r.Entidade) == \"<NA>\"}\n",
    "    )\n",
    "    df = df.groupby(\"Id\", as_index=False).first()  # remove duplicated with NaNs\n",
    "    df.dropna(subset=[\"Status\"], inplace=True)\n",
    "    df = df[df.Status.str.contains(\"-C1$|-C2$|-C3$|-C4$|-C7|-C98$\")].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atualização das bases de dados\n",
    "As bases de dados são atualizadas atráves das funções a seguir, o único argumento passado em todas elas é a pasta na qual os arquivos locais processados serão salvos, os nomes dos arquivos são padronizados e não podem ser editados para que as funções de leitura e processamento recebam somente a pasta na qual esses arquivos foram salvos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def update_radcom(pasta):\n",
    "    \"\"\"Atualiza a tabela local retornada pela query `RADCOM`\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"[cyan]Lendo o Banco de Dados de Radcom...\", spinner=\"earth\"\n",
    "    ) as status:\n",
    "        try:\n",
    "            conn = connect_db()\n",
    "            df = pd.read_sql_query(RADCOM, conn)\n",
    "            df[\"Unidade\"] = \"MHz\"\n",
    "            df = df_optimize(df, exclude=[\"Frequência\"])\n",
    "            try:\n",
    "                df.to_feather(f\"{pasta}/radcom.fth\")\n",
    "            except ArrowInvalid:\n",
    "                Path(f\"{pasta}/radcom.fth\").unlink()\n",
    "                df.to_excel(f\"{pasta}/radcom.xlsx\", engine=\"openpyxl\", index=False)\n",
    "        except pyodbc.OperationalError:\n",
    "            status.console.log(\n",
    "                \"Não foi possível abrir uma conexão com o SQL Server. Esta conexão somente funciona da rede cabeada!\"\n",
    "            )\n",
    "\n",
    "\n",
    "def update_stel(pasta):\n",
    "    \"\"\"Atualiza a tabela local retornada pela query `STEL`\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"[red]Lendo o Banco de Dados do STEL. Processo Lento, aguarde...\",\n",
    "        spinner=\"moon\",\n",
    "    ) as status:\n",
    "        try:\n",
    "            conn = connect_db()\n",
    "            df = pd.read_sql_query(STEL, conn)\n",
    "            df[\"Validade_RF\"] = df.Validade_RF.astype(\"str\").str.slice(0, 10)\n",
    "            df[\"Num_Serviço\"] = df.Num_Serviço.astype(\"category\")\n",
    "            df.loc[df.Unidade == \"kHz\", \"Frequência\"] = df.loc[\n",
    "                df.Unidade == \"kHz\", \"Frequência\"\n",
    "            ].apply(lambda x: Decimal(x) / Decimal(1000))\n",
    "            df.loc[df.Unidade == \"GHz\", \"Frequência\"] = df.loc[\n",
    "                df.Unidade == \"GHz\", \"Frequência\"\n",
    "            ].apply(lambda x: Decimal(x) * Decimal(1000))\n",
    "            df[\"Frequência\"] = df.Frequência.astype(\"float\")\n",
    "            df.loc[df.Unidade == \"kHz\", \"Unidade\"] = \"MHz\"\n",
    "            df = df_optimize(df, exclude=[\"Frequência\"])\n",
    "            try:\n",
    "                df.to_feather(f\"{pasta}/stel.fth\")\n",
    "            except ArrowInvalid:\n",
    "                Path(f\"{pasta}/stel.fth\").unlink()\n",
    "                df.to_excel(f\"{pasta}/stel.xlsx\", engine=\"openpyxl\", index=False)\n",
    "        except pyodbc.OperationalError:\n",
    "            status.console.log(\n",
    "                \"Não foi possível abrir uma conexão com o SQL Server. Esta conexão somente funciona da rede cabeada!\"\n",
    "            )\n",
    "\n",
    "\n",
    "def update_mosaico(pasta):\n",
    "    \"\"\"Atualiza a tabela local do Mosaico. É baixado e processado arquivos xml zipados da página pública do Spectrum E\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"[blue]Baixando as Estações do Mosaico...\", spinner=\"shark\"\n",
    "    ) as status:\n",
    "        file = requests.get(ESTACOES)\n",
    "        with open(f\"{pasta}/estações.zip\", \"wb\") as estações:\n",
    "            estações.write(file.content)\n",
    "    with console.status(\n",
    "        \"[blue]Baixando o Plano Básico das Estações...\", spinner=\"weather\"\n",
    "    ) as status:\n",
    "        file = requests.get(PLANO_BASICO)\n",
    "        with open(f\"{pasta}/Canais.zip\", \"wb\") as plano_basico:\n",
    "            plano_basico.write(file.content)\n",
    "    console.print(\":package: [blue]Consolidando as bases de dados...\")\n",
    "    estações = _read_estações(f\"{pasta}/estações.zip\")\n",
    "    plano_basico = _read_plano_basico(f\"{pasta}/Canais.zip\")\n",
    "    df = estações.merge(plano_basico, on=\"Id\", how=\"left\")\n",
    "    df[\"Número_da_Estação\"] = df[\"Número_da_Estação\"].fillna(-1)\n",
    "    df[\"Número_da_Estação\"] = df[\"Número_da_Estação\"].astype(\"int\")\n",
    "    df = clean_mosaico(pasta, df)\n",
    "    try:\n",
    "        df.reset_index(drop=True).to_feather(f\"{pasta}/mosaico.fth\")\n",
    "    except ArrowInvalid:\n",
    "        Path(f\"{pasta}/mosaico.fth\").unlink()\n",
    "        with pd.ExcelWriter(f\"{pasta}/mosaico.xlsx\") as workbook:\n",
    "            df.reset_index(drop=True).to_excel(\n",
    "                workbook, sheet_name=\"Sheet1\", engine=\"openpyxl\", index=False\n",
    "            )\n",
    "    Path(f\"{pasta}/estações.zip\").unlink()\n",
    "    Path(f\"{pasta}/Canais.zip\").unlink()\n",
    "    return df\n",
    "\n",
    "def update_base(pasta):\n",
    "    \"\"\"Wrapper que atualiza opcionalmente lê e atualiza as três bases indicadas anteriormente, as combina e salva o arquivo consolidado na pasta `pasta`\"\"\"\n",
    "    console = Console()\n",
    "    stel = update_stel(pasta).loc[:, TELECOM]\n",
    "    radcom = update_radcom(pasta)\n",
    "    mosaico = update_mosaico(pasta)\n",
    "    radcom[\"Num_Serviço\"] = \"231\"\n",
    "    radcom[\"Status\"] = \"RADCOM\"\n",
    "    radcom[\"Classe_Emissão\"] = \"\"\n",
    "    radcom[\"Largura_Emissão\"] = BW_MAP['231']\n",
    "    filtro = radcom.Fase.notna() & radcom.Situação.notna()\n",
    "    radcom.loc[filtro, \"Classe\"] = radcom.loc[filtro, \"Fase\"].astype(\"string\") + '-' + radcom.loc[filtro, \"Situação\"].astype(\"string\")\n",
    "    radcom[\"Entidade\"] = radcom.Entidade.str.rstrip().str.lstrip()\n",
    "    radcom[\"Num_Ato\"] = \"-1\"\n",
    "    radcom[\"Data_Ato\"] = \"\"\n",
    "    radcom[\"Validade_RF\"] = \"\"\n",
    "    radcom[\"Fonte\"] = \"SRD\"\n",
    "    radcom = df_optimize(radcom, exclude=[\"Frequência\"])\n",
    "    stel[\"Status\"] = \"L\"\n",
    "    stel[\"Num_Ato\"] = \"-1\"\n",
    "    stel[\"Data_Ato\"] = \"\"\n",
    "    stel[\"Entidade\"] = stel.Entidade.str.rstrip().str.lstrip()\n",
    "    stel[\"Fonte\"] = \"STEL\"\n",
    "    stel = df_optimize(stel, exclude=[\"Frequência\"])\n",
    "    mosaico[\"Fonte\"] = \"MOS\"\n",
    "    mosaico[\"Classe_Emissão\"] = \"\"\n",
    "    mosaico[\"Largura_Emissão\"] = mosaico.Num_Serviço.map(BW_MAP)\n",
    "    mosaico = mosaico.loc[:, RADIODIFUSAO]\n",
    "    mosaico = df_optimize(mosaico, exclude=[\"Frequência\"])\n",
    "    rd = (\n",
    "        pd.concat([mosaico, radcom, stel])\n",
    "        .sort_values(\"Frequência\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    rd[\"Num_Serviço\"] = rd.Num_Serviço.astype(\"int\")\n",
    "    rd = df_optimize(rd, exclude=[\"Frequência\"])\n",
    "    rd = rd.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "    rd['BW(kHz)'] = rd.Largura_Emissão.apply(parse_bw)\n",
    "    console.print(\":trophy: [green]Base Consolidada. Salvando os arquivos...\")\n",
    "    try:\n",
    "        rd.to_feather(f\"{pasta}/base.fth\")\n",
    "    except ArrowInvalid:\n",
    "        Path(f\"{pasta}/base.fth\").unlink()\n",
    "        with pd.ExcelWriter(f\"{pasta}/base.xlsx\") as workbook:\n",
    "            rd.to_excel(workbook, sheet_name=\"Sheet1\", engine=\"openpyxl\", index=False)\n",
    "    return rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted constants.ipynb.\n",
      "Converted filter.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted queries.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "737b3e0e8750f89ce31674571febe5a5a08e902b32bb8cbee589bdf91ca77e61"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('db')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
