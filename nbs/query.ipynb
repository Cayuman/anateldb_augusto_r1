{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp query\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries\n",
    "\n",
    "> Este módulo executa as queries sql / MongoDB necessárias para baixar os dados do STEL, RADCOM e MOSAICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from decimal import Decimal, getcontext\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from fastcore.test import *\n",
    "from rich.console import Console\n",
    "from pyarrow import ArrowInvalid\n",
    "import pandas_read_xml as pdx\n",
    "from unidecode import unidecode\n",
    "from fastcore.foundation import L\n",
    "from fastcore.utils import listify\n",
    "\n",
    "\n",
    "from anateldb.constants import *\n",
    "from anateldb.format import df_optimize, parse_bw, dict2cols\n",
    "from anateldb.merge import clean_mosaico\n",
    "\n",
    "getcontext().prec = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conexão com o banco de dados\n",
    "A função a seguir é um `wrapper` simples que utiliza o `pyodbc` para se conectar ao banco de dados base da Anatel e retorna o objeto da conexão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def connect_db():\n",
    "    \"\"\"Conecta ao Banco ANATELBDRO01 e retorna o 'cursor' (iterador) do Banco pronto para fazer iterações\"\"\"\n",
    "    return pyodbc.connect(\n",
    "        \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "        \"Server=ANATELBDRO01;\"\n",
    "        \"Database=SITARWEB;\"\n",
    "        \"Trusted_Connection=yes;\"\n",
    "        \"MultipleActiveResultSets=True;\",\n",
    "        timeout=TIMEOUT,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "def test_connection():\n",
    "    conn = connect_db()\n",
    "    cursor = conn.cursor()\n",
    "    for query in (RADCOM,):\n",
    "        cursor.execute(query)\n",
    "        test_eq(type(cursor.fetchone()), pyodbc.Row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _read_estações(path: Union[str, Path])->pd.DataFrame:\n",
    "    \"\"\"Read the zipped xml file `Estações.zip` from MOSAICO and returns a dataframe\"\"\"\n",
    "    def extrair_ato(row):\n",
    "        if not isinstance(row, str):\n",
    "            row = listify(row)[::-1]\n",
    "            for d in row:\n",
    "                if not isinstance(d, dict):\n",
    "                    continue\n",
    "                if (d.get(\"@TipoDocumento\") == \"Ato\") and (\n",
    "                    d.get(\"@Razao\") == \"Autoriza o Uso de Radiofrequência\"\n",
    "                ):\n",
    "                    return d[\"@NumDocumento\"], d[\"@DataDOU\"][:10]\n",
    "            return \"\", \"\"\n",
    "        return \"\", \"\"\n",
    "\n",
    "    es = pdx.read_xml(path, [\"estacao_rd\"])\n",
    "    dfs = []\n",
    "    for i in range(es.shape[0]):\n",
    "        df = pd.DataFrame(es[\"row\"][i]).replace(\"\", pd.NA)\n",
    "        df = dict2cols(df)\n",
    "        df.columns = [unidecode(c).lower().replace(\"@\", \"\") for c in df.columns]\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs)\n",
    "    df = df[df.state.str.contains(\"-C1$|-C2$|-C3$|-C4$|-C7|-C98$\")].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    docs = L(df.historico_documentos.apply(extrair_ato).tolist())\n",
    "    df = df.loc[:, COL_ESTACOES]\n",
    "    df[\"Num_Ato\"] = docs.itemgot(0).map(str)\n",
    "    df[\"Data_Ato\"] = docs.itemgot(1).map(str)\n",
    "    df.columns = NEW_ESTACOES\n",
    "    df[\"Validade_RF\"] = df.Validade_RF.astype(\"string\").str.slice(0, 10)\n",
    "    df[\"Data_Ato\"] = df.Data_Ato.str.slice(0, 10)\n",
    "    for c in df.columns:\n",
    "        df.loc[df[c] == \"\", c] = pd.NA\n",
    "    return df\n",
    "\n",
    "\n",
    "def _read_plano_basico(path: Union[str, Path])->pd.DataFrame:\n",
    "    \"\"\"Read the zipped xml file `Plano_Básico.zip` from MOSAICO and returns a dataframe\"\"\"\n",
    "    pb = pdx.read_xml(path, [\"plano_basico\"])\n",
    "    dfs = []\n",
    "    for i in range(pb.shape[0]):\n",
    "        df = pd.DataFrame(pb[\"row\"][i]).replace(\"\", pd.NA)\n",
    "        df = dict2cols(df)\n",
    "        df.columns = [unidecode(c).lower().replace(\"@\", \"\") for c in df.columns]\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs)\n",
    "    df = df.loc[df.pais == \"BRA\", COL_PB].reset_index(drop=True)\n",
    "    for c in df.columns:\n",
    "        df.loc[df[c] == \"\", c] = pd.NA\n",
    "    df.columns = NEW_PB\n",
    "    df.sort_values([\"Id\", \"Canal\"], inplace=True)\n",
    "    ENTIDADES.update(\n",
    "        {r.Fistel: r.Entidade for r in df.itertuples() if str(r.Entidade) == \"<NA>\"}\n",
    "    )\n",
    "    df = df.groupby(\"Id\", as_index=False).first()  # remove duplicated with NaNs\n",
    "    df.dropna(subset=[\"Status\"], inplace=True)\n",
    "    df = df[df.Status.str.contains(\"-C1$|-C2$|-C3$|-C4$|-C7|-C98$\")].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (path := Path.cwd() / 'estações.zip').exists():\n",
    "    e = _read_estações(str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import URLError\n",
    "req = Request(ESTACAO)\n",
    "try:\n",
    "    response = urlopen(req)\n",
    "except URLError as e:\n",
    "    if hasattr(e, 'reason'):\n",
    "        print('We failed to reach a server.')\n",
    "        print('Reason: ', e.reason)\n",
    "    elif hasattr(e, 'code'):\n",
    "        print('The server couldn\\'t fulfill the request.')\n",
    "        print('Error code: ', e.code)\n",
    "else:\n",
    "    Path.cwd().joinpath('estações.zip').write_bytes(response.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<urllib.request.Request at 0x1b2131e34c0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atualização das bases de dados\n",
    "As bases de dados são atualizadas atráves das funções a seguir, o único argumento passado em todas elas é a pasta na qual os arquivos locais processados serão salvos, os nomes dos arquivos são padronizados e não podem ser editados para que as funções de leitura e processamento recebam somente a pasta na qual esses arquivos foram salvos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def update_radcom(pasta: Union[str, Path])->pd.DataFrame:\n",
    "    \"\"\"Atualiza a tabela local retornada pela query `RADCOM`\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"[cyan]Lendo o Banco de Dados de Radcom...\", spinner=\"earth\"\n",
    "    ) as status:\n",
    "        try:\n",
    "            conn = connect_db()\n",
    "            df = pd.read_sql_query(RADCOM, conn)\n",
    "            df[\"Unidade\"] = \"MHz\"\n",
    "            df = df_optimize(df, exclude=[\"Frequência\"])\n",
    "            try:\n",
    "                df.to_feather(f\"{pasta}/radcom.fth\")\n",
    "            except ArrowInvalid:\n",
    "                Path(f\"{pasta}/radcom.fth\").unlink()\n",
    "                df.to_excel(f\"{pasta}/radcom.xlsx\", engine=\"openpyxl\", index=False)\n",
    "        except pyodbc.OperationalError:\n",
    "            status.console.log(\n",
    "                \"Não foi possível abrir uma conexão com o SQL Server. Esta conexão somente funciona da rede cabeada!\"\n",
    "            )\n",
    "    return df\n",
    "\n",
    "\n",
    "def update_stel(pasta: Union[str, Path])->pd.DataFrame:\n",
    "    \"\"\"Atualiza a tabela local retornada pela query `STEL`\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"[red]Lendo o Banco de Dados do STEL. Processo Lento, aguarde...\",\n",
    "        spinner=\"moon\",\n",
    "    ) as status:\n",
    "        try:\n",
    "            conn = connect_db()\n",
    "            df = pd.read_sql_query(STEL, conn)\n",
    "            df[\"Validade_RF\"] = df.Validade_RF.astype(\"str\").str.slice(0, 10)\n",
    "            df[\"Num_Serviço\"] = df.Num_Serviço.astype(\"category\")\n",
    "            df.loc[df.Unidade == \"kHz\", \"Frequência\"] = df.loc[\n",
    "                df.Unidade == \"kHz\", \"Frequência\"\n",
    "            ].apply(lambda x: Decimal(x) / Decimal(1000))\n",
    "            df.loc[df.Unidade == \"GHz\", \"Frequência\"] = df.loc[\n",
    "                df.Unidade == \"GHz\", \"Frequência\"\n",
    "            ].apply(lambda x: Decimal(x) * Decimal(1000))\n",
    "            df[\"Frequência\"] = df.Frequência.astype(\"float\")\n",
    "            df.loc[df.Unidade == \"kHz\", \"Unidade\"] = \"MHz\"\n",
    "            df = df_optimize(df, exclude=[\"Frequência\"])\n",
    "            try:\n",
    "                df.to_feather(f\"{pasta}/stel.fth\")\n",
    "            except ArrowInvalid:\n",
    "                Path(f\"{pasta}/stel.fth\").unlink()\n",
    "                df.to_excel(f\"{pasta}/stel.xlsx\", engine=\"openpyxl\", index=False)\n",
    "        except pyodbc.OperationalError:\n",
    "            status.console.log(\n",
    "                \"Não foi possível abrir uma conexão com o SQL Server. Esta conexão somente funciona da rede cabeada!\"\n",
    "            )\n",
    "    return df\n",
    "\n",
    "\n",
    "def update_mosaico(pasta: Union[str, Path])->pd.DataFrame:\n",
    "    \"\"\"Atualiza a tabela local do Mosaico. É baixado e processado arquivos xml zipados da página pública do Spectrum E\"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\n",
    "        \"[blue]Baixando as Estações do Mosaico...\", spinner=\"shark\"\n",
    "    ) as status:\n",
    "        stations, _ = urlretrieve(ESTACOES, f\"{pasta}/estações.zip\")\n",
    "    with console.status(\n",
    "        \"[blue]Baixando o Plano Básico das Estações...\", spinner=\"weather\"\n",
    "    ) as status:\n",
    "        pb, _ = urlretrieve(PLANO_BASICO, f\"{pasta}/canais.zip\")\n",
    "    console.print(\":package: [blue]Consolidando as bases de dados...\")\n",
    "    estações = _read_estações(stations)\n",
    "    plano_basico = _read_plano_basico(pb)\n",
    "    df = estações.merge(plano_basico, on=\"Id\", how=\"left\")\n",
    "    df[\"Número_da_Estação\"] = df[\"Número_da_Estação\"].fillna('-1')\n",
    "    df[\"Número_da_Estação\"] = df[\"Número_da_Estação\"].astype(\"string\")\n",
    "    df = clean_mosaico(pasta, df)\n",
    "    try:\n",
    "        df.reset_index(drop=True).to_feather(f\"{pasta}/mosaico.fth\")\n",
    "    except ArrowInvalid:\n",
    "        Path(f\"{pasta}/mosaico.fth\").unlink()\n",
    "        with pd.ExcelWriter(f\"{pasta}/mosaico.xlsx\") as workbook:\n",
    "            df.reset_index(drop=True).to_excel(\n",
    "                workbook, sheet_name=\"Sheet1\", engine=\"openpyxl\", index=False\n",
    "            )\n",
    "    Path(stations).unlink()\n",
    "    Path(pb).unlink()\n",
    "    return df\n",
    "\n",
    "def update_base(pasta: Union[str, Path])->pd.DataFrame:\n",
    "    \"\"\"Wrapper que atualiza opcionalmente lê e atualiza as três bases indicadas anteriormente, as combina e salva o arquivo consolidado na pasta `pasta`\"\"\"\n",
    "    console = Console()\n",
    "    stel = update_stel(pasta).loc[:, TELECOM]\n",
    "    radcom = update_radcom(pasta)\n",
    "    mosaico = update_mosaico(pasta)\n",
    "    radcom[\"Num_Serviço\"] = \"231\"\n",
    "    radcom[\"Status\"] = \"RADCOM\"\n",
    "    radcom[\"Classe_Emissão\"] = \"\"\n",
    "    radcom[\"Largura_Emissão\"] = BW_MAP['231']\n",
    "    filtro = radcom.Fase.notna() & radcom.Situação.notna()\n",
    "    radcom.loc[filtro, \"Classe\"] = radcom.loc[filtro, \"Fase\"].astype(\"string\") + '-' + radcom.loc[filtro, \"Situação\"].astype(\"string\")\n",
    "    radcom[\"Entidade\"] = radcom.Entidade.str.rstrip().str.lstrip()\n",
    "    radcom[\"Num_Ato\"] = \"-1\"\n",
    "    radcom[\"Data_Ato\"] = \"\"\n",
    "    radcom[\"Validade_RF\"] = \"\"\n",
    "    radcom[\"Fonte\"] = \"SRD\"\n",
    "    radcom = df_optimize(radcom, exclude=[\"Frequência\"])\n",
    "    stel[\"Status\"] = \"L\"\n",
    "    stel[\"Num_Ato\"] = \"-1\"\n",
    "    stel[\"Data_Ato\"] = \"\"\n",
    "    stel[\"Entidade\"] = stel.Entidade.str.rstrip().str.lstrip()\n",
    "    stel[\"Fonte\"] = \"STEL\"\n",
    "    stel = df_optimize(stel, exclude=[\"Frequência\"])\n",
    "    mosaico[\"Fonte\"] = \"MOS\"\n",
    "    mosaico[\"Classe_Emissão\"] = \"\"\n",
    "    mosaico[\"Largura_Emissão\"] = mosaico.Num_Serviço.map(BW_MAP)\n",
    "    mosaico = mosaico.loc[:, RADIODIFUSAO]\n",
    "    mosaico = df_optimize(mosaico, exclude=[\"Frequência\"])\n",
    "    rd = (\n",
    "        pd.concat([mosaico, radcom, stel])\n",
    "        .sort_values(\"Frequência\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    rd[\"Num_Serviço\"] = rd.Num_Serviço.astype(\"int\")\n",
    "    rd = df_optimize(rd, exclude=[\"Frequência\"])\n",
    "    rd = rd.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "    rd['BW(kHz)'] = rd.Largura_Emissão.apply(parse_bw)\n",
    "    console.print(\":trophy: [green]Base Consolidada. Salvando os arquivos...\")\n",
    "    try:\n",
    "        rd.to_feather(f\"{pasta}/base.fth\")\n",
    "    except ArrowInvalid:\n",
    "        Path(f\"{pasta}/base.fth\").unlink()\n",
    "        with pd.ExcelWriter(f\"{pasta}/base.xlsx\") as workbook:\n",
    "            rd.to_excel(workbook, sheet_name=\"Sheet1\", engine=\"openpyxl\", index=False)\n",
    "    return rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted constants.ipynb.\n",
      "Converted filter.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted queries.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb8 in position 12: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mg:\\OneDrive - ANATEL\\anateldb\\nbs\\query.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20ANATEL/anateldb/nbs/query.ipynb#ch0000009?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgazpacho\u001b[39;00m \u001b[39mimport\u001b[39;00m Soup, get\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20ANATEL/anateldb/nbs/query.ipynb#ch0000009?line=1'>2</a>\u001b[0m e \u001b[39m=\u001b[39m get(ESTACOES)\n",
      "File \u001b[1;32mc:\\Users\\rsilva\\Miniconda3\\envs\\db\\lib\\site-packages\\gazpacho\\get.py:41\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, headers)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/site-packages/gazpacho/get.py?line=38'>39</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/site-packages/gazpacho/get.py?line=39'>40</a>\u001b[0m     \u001b[39mwith\u001b[39;00m opener\u001b[39m.\u001b[39mopen(url) \u001b[39mas\u001b[39;00m response:\n\u001b[1;32m---> <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/site-packages/gazpacho/get.py?line=40'>41</a>\u001b[0m         content \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39;49mread()\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/site-packages/gazpacho/get.py?line=41'>42</a>\u001b[0m         \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget_content_type() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/site-packages/gazpacho/get.py?line=42'>43</a>\u001b[0m             content \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(content)\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb8 in position 12: invalid start byte"
     ]
    }
   ],
   "source": [
    "from gazpacho import Soup, get\n",
    "e = get(ESTACOES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = urlretrieve(ESTACOES, Path.cwd() / \"estações.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HTTPResponse' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mg:\\OneDrive - ANATEL\\anateldb\\nbs\\query.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20ANATEL/anateldb/nbs/query.ipynb#ch0000015?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m urlopen(ESTACAO) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20ANATEL/anateldb/nbs/query.ipynb#ch0000015?line=1'>2</a>\u001b[0m     e \u001b[39m=\u001b[39m _read_estações(f)\n",
      "\u001b[1;32mg:\\OneDrive - ANATEL\\anateldb\\nbs\\query.ipynb Cell 8'\u001b[0m in \u001b[0;36m_read_estações\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20ANATEL/anateldb/nbs/query.ipynb#ch0000010?line=13'>14</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20ANATEL/anateldb/nbs/query.ipynb#ch0000010?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20ANATEL/anateldb/nbs/query.ipynb#ch0000010?line=16'>17</a>\u001b[0m es \u001b[39m=\u001b[39m pdx\u001b[39m.\u001b[39;49mread_xml(path, [\u001b[39m\"\u001b[39;49m\u001b[39mestacao_rd\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20ANATEL/anateldb/nbs/query.ipynb#ch0000010?line=17'>18</a>\u001b[0m dfs \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/OneDrive%20-%20ANATEL/anateldb/nbs/query.ipynb#ch0000010?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(es\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\rsilva\\Miniconda3\\envs\\db\\lib\\site-packages\\pandas_read_xml.py:25\u001b[0m, in \u001b[0;36mread_xml\u001b[1;34m(path_or_xml, root_key_list, root_is_rows, transpose, encoding)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/site-packages/pandas_read_xml.py?line=23'>24</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_xml\u001b[39m(path_or_xml: \u001b[39mstr\u001b[39m, root_key_list: Optional[List[\u001b[39mstr\u001b[39m]]\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, root_is_rows: \u001b[39mbool\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, transpose: \u001b[39mbool\u001b[39m\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, encoding: Optional[\u001b[39mstr\u001b[39m]\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m---> <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/site-packages/pandas_read_xml.py?line=24'>25</a>\u001b[0m     \u001b[39mif\u001b[39;00m urllib\u001b[39m.\u001b[39;49mparse\u001b[39m.\u001b[39;49murlparse(path_or_xml)\u001b[39m.\u001b[39mscheme \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mhttp\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttps\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/site-packages/pandas_read_xml.py?line=25'>26</a>\u001b[0m         \u001b[39mif\u001b[39;00m path_or_xml\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.zip\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/site-packages/pandas_read_xml.py?line=26'>27</a>\u001b[0m             \u001b[39mwith\u001b[39;00m get_zip_file_from_url(path_or_xml) \u001b[39mas\u001b[39;00m zf:\n",
      "File \u001b[1;32mc:\\Users\\rsilva\\Miniconda3\\envs\\db\\lib\\urllib\\parse.py:375\u001b[0m, in \u001b[0;36murlparse\u001b[1;34m(url, scheme, allow_fragments)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=368'>369</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39murlparse\u001b[39m(url, scheme\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, allow_fragments\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=369'>370</a>\u001b[0m     \u001b[39m\"\"\"Parse a URL into 6 components:\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=370'>371</a>\u001b[0m \u001b[39m    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=371'>372</a>\u001b[0m \u001b[39m    Return a 6-tuple: (scheme, netloc, path, params, query, fragment).\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=372'>373</a>\u001b[0m \u001b[39m    Note that we don't break the components up in smaller bits\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=373'>374</a>\u001b[0m \u001b[39m    (e.g. netloc is a single string) and we don't expand % escapes.\"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=374'>375</a>\u001b[0m     url, scheme, _coerce_result \u001b[39m=\u001b[39m _coerce_args(url, scheme)\n\u001b[0;32m    <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=375'>376</a>\u001b[0m     splitresult \u001b[39m=\u001b[39m urlsplit(url, scheme, allow_fragments)\n\u001b[0;32m    <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=376'>377</a>\u001b[0m     scheme, netloc, url, query, fragment \u001b[39m=\u001b[39m splitresult\n",
      "File \u001b[1;32mc:\\Users\\rsilva\\Miniconda3\\envs\\db\\lib\\urllib\\parse.py:127\u001b[0m, in \u001b[0;36m_coerce_args\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=124'>125</a>\u001b[0m \u001b[39mif\u001b[39;00m str_input:\n\u001b[0;32m    <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=125'>126</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m args \u001b[39m+\u001b[39m (_noop,)\n\u001b[1;32m--> <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=126'>127</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _decode_args(args) \u001b[39m+\u001b[39m (_encode_result,)\n",
      "File \u001b[1;32mc:\\Users\\rsilva\\Miniconda3\\envs\\db\\lib\\urllib\\parse.py:111\u001b[0m, in \u001b[0;36m_decode_args\u001b[1;34m(args, encoding, errors)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=108'>109</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decode_args\u001b[39m(args, encoding\u001b[39m=\u001b[39m_implicit_encoding,\n\u001b[0;32m    <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=109'>110</a>\u001b[0m                        errors\u001b[39m=\u001b[39m_implicit_errors):\n\u001b[1;32m--> <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=110'>111</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39;49m(x\u001b[39m.\u001b[39;49mdecode(encoding, errors) \u001b[39mif\u001b[39;49;00m x \u001b[39melse\u001b[39;49;00m \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m args)\n",
      "File \u001b[1;32mc:\\Users\\rsilva\\Miniconda3\\envs\\db\\lib\\urllib\\parse.py:111\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=108'>109</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decode_args\u001b[39m(args, encoding\u001b[39m=\u001b[39m_implicit_encoding,\n\u001b[0;32m    <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=109'>110</a>\u001b[0m                        errors\u001b[39m=\u001b[39m_implicit_errors):\n\u001b[1;32m--> <a href='file:///c%3A/Users/rsilva/Miniconda3/envs/db/lib/urllib/parse.py?line=110'>111</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(x\u001b[39m.\u001b[39;49mdecode(encoding, errors) \u001b[39mif\u001b[39;00m x \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m args)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HTTPResponse' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "\n",
    "with urlopen(ESTACAO) as f:\n",
    "    e = _read_estações(f)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "737b3e0e8750f89ce31674571febe5a5a08e902b32bb8cbee589bdf91ca77e61"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('db')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
