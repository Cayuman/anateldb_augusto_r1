# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/query.ipynb (unless otherwise specified).

__all__ = ['connect_db', 'formatar_tipos', 'save_df', 'update_radcom', 'update_stel', 'update_mosaico', 'update_base']

# Cell
from decimal import Decimal, getcontext
from typing import Union
from urllib.request import urlretrieve
from numpy import save


import pandas as pd
import pyodbc
from rich.console import Console
from pyarrow import ArrowInvalid
import pandas_read_xml as pdx
from unidecode import unidecode
from fastcore.xtras import Path
from fastcore.foundation import L
from fastcore.utils import listify


from .constants import *
from .format import optimize_objects, parse_bw, dict2cols
from .merge import clean_mosaico

getcontext().prec = 5

# Cell
def connect_db():
    """Conecta ao Banco ANATELBDRO01 e retorna o 'cursor' (iterador) do Banco pronto para fazer iterações"""
    return pyodbc.connect(
        "Driver={ODBC Driver 17 for SQL Server};"
        "Server=ANATELBDRO01;"
        "Database=SITARWEB;"
        "Trusted_Connection=yes;"
        "MultipleActiveResultSets=True;",
        timeout=TIMEOUT,
    )

# Internal Cell
def _read_estações(path: Union[str, Path]) -> pd.DataFrame:
    """Read the zipped xml file `Estações.zip` from MOSAICO and returns a dataframe"""

    def extrair_ato(row):
        if not isinstance(row, str):
            row = listify(row)[::-1]
            for d in row:
                if not isinstance(d, dict):
                    continue
                if (d.get("@TipoDocumento") == "Ato") and (
                    d.get("@Razao") == "Autoriza o Uso de Radiofrequência"
                ):
                    return d["@NumDocumento"], d["@DataDOU"][:10]
            return "", ""
        return "", ""

    es = pdx.read_xml(path, ["estacao_rd"])
    dfs = []
    for i in range(es.shape[0]):
        df = pd.DataFrame(es["row"][i]).replace("", pd.NA)
        df = dict2cols(df)
        df.columns = [unidecode(c).lower().replace("@", "") for c in df.columns]
        dfs.append(df)
    df = pd.concat(dfs)
    df = df[df.state.str.contains("-C1$|-C2$|-C3$|-C4$|-C7|-C98$")].reset_index(
        drop=True
    )
    docs = L(df.historico_documentos.apply(extrair_ato).tolist())
    df = df.loc[:, COL_ESTACOES]
    df["Num_Ato"] = docs.itemgot(0).map(str)
    df["Data_Ato"] = docs.itemgot(1).map(str)
    df.columns = NEW_ESTACOES
    df["Validade_RF"] = df.Validade_RF.astype("string").str.slice(0, 10)
    df["Data_Ato"] = df.Data_Ato.str.slice(0, 10)
    for c in df.columns:
        df.loc[df[c] == "", c] = pd.NA
    return df


def _read_plano_basico(path: Union[str, Path]) -> pd.DataFrame:
    """Read the zipped xml file `Plano_Básico.zip` from MOSAICO and returns a dataframe"""
    pb = pdx.read_xml(path, ["plano_basico"])
    dfs = []
    for i in range(pb.shape[0]):
        df = pd.DataFrame(pb["row"][i]).replace("", pd.NA)
        df = dict2cols(df)
        df.columns = [unidecode(c).lower().replace("@", "") for c in df.columns]
        dfs.append(df)
    df = pd.concat(dfs)
    df = df.loc[df.pais == "BRA", COL_PB].reset_index(drop=True)
    for c in df.columns:
        df.loc[df[c] == "", c] = pd.NA
    df.columns = NEW_PB
    df.sort_values(["Id", "Canal"], inplace=True)
    ENTIDADES.update(
        {r.Fistel: r.Entidade for r in df.itertuples() if str(r.Entidade) == "<NA>"}
    )
    df = df.groupby("Id", as_index=False).first()  # remove duplicated with NaNs
    df.dropna(subset=["Status"], inplace=True)
    df = df[df.Status.str.contains("-C1$|-C2$|-C3$|-C4$|-C7|-C98$")].reset_index(
        drop=True
    )
    return df

# Cell
def formatar_tipos(df: pd.DataFrame, stem: str = None) -> pd.DataFrame:
    """Convert the types of a dataframe"""
    df["Frequência"] = df["Frequência"].astype("category")
    df["Latitude"] = df["Latitude"].astype("float32")
    df["Longitude"] = df["Longitude"].astype("float32")
    df["Entidade"] = df["Entidade"].astype("string")
    df["Fistel"] = df["Fistel"].astype("string")
    df["Município"] = df["Município"].astype("category")
    df["UF"] = df["UF"].astype("category")
    df["CNPJ"] = df["CNPJ"].astype("string")
    df["Número_da_Estação"] = df["Número_da_Estação"].astype("string")
    df["Num_Serviço"] = df["Num_Serviço"].astype("category")
    if stem == "stel":
        df["Validade_RF"] = df.Validade_RF.astype("string").str.slice(0, 10)
        df.loc[df.Unidade == "kHz", "Frequência"] = df.loc[
            df.Unidade == "kHz", "Frequência"
        ].apply(lambda x: Decimal(x) / Decimal(1000))
        df.loc[df.Unidade == "GHz", "Frequência"] = df.loc[
            df.Unidade == "GHz", "Frequência"
        ].apply(lambda x: Decimal(x) * Decimal(1000))
        df.drop("Unidade", axis=1, inplace=True)
    elif stem == "radcom":
        a = df.Situação.isna()
        df.loc[a, "Classe"] = df.loc[a, "Fase"]
        df.loc[~a, "Classe"] = (
            df.loc[~a, "Fase"].astype("string")
            + "-"
            + df.loc[~a, "Situação"].astype("string")
        )
        df["Classe"] = df["Classe"].astype("category")
        df.drop(["Fase", "Situação"], axis=1, inplace=True)
    return optimize_objects(df)


def save_df(df: pd.DataFrame, folder: Union[str, Path], stem: str) -> pd.DataFrame:
    """Format, Save and return a dataframe"""
    df = formatar_tipos(df, stem)
    try:
        file = Path(f"{folder}/{stem}.parquet.gzip")
        df.to_parquet(file, compression="gzip")
    except ArrowInvalid:
        file.unlink()
        try:
            file = Path(f"{folder}/{stem}.fth")
            df.to_feather(file)
        except ArrowInvalid:
            file.unlink()
            try:
                file = Path(f"{folder}/{stem}.xlsx")
                with pd.ExcelWriter(file) as wb:
                    df.to_excel(
                        wb, sheet_name="DataBase", engine="openpyxl", index=False
                    )
            except Exception as e:
                raise ValueError(f"Could not save {stem} to {file}") from e
    return df


def update_radcom(folder: Union[str, Path]) -> pd.DataFrame:
    """Atualiza a tabela local retornada pela query `RADCOM`"""
    console = Console()
    with console.status(
        "[cyan]Lendo o Banco de Dados de Radcom...", spinner="earth"
    ) as status:
        try:
            conn = connect_db()
            df = pd.read_sql_query(RADCOM, conn)
            return save_df(df, folder, "radcom")
        except pyodbc.OperationalError:
            status.console.log(
                "Não foi possível abrir uma conexão com o SQL Server. Esta conexão somente funciona da rede cabeada!"
            )
    return None


def update_stel(folder: Union[str, Path]) -> pd.DataFrame:
    """Atualiza a tabela local retornada pela query `STEL`"""
    console = Console()
    with console.status(
        "[red]Lendo o Banco de Dados do STEL. Processo Lento, aguarde...",
        spinner="bouncingBall",
    ) as status:
        try:
            conn = connect_db()
            df = pd.read_sql_query(STEL, conn)
            return save_df(df, folder, "stel")
        except pyodbc.OperationalError:
            status.console.log(
                "Não foi possível abrir uma conexão com o SQL Server. Esta conexão somente funciona da rede cabeada!"
            )
    return df


def update_mosaico(folder: Union[str, Path]) -> pd.DataFrame:
    """Atualiza a tabela local do Mosaico. É baixado e processado arquivos xml zipados da página pública do Spectrum E"""
    console = Console()
    with console.status(
        "[blue]Baixando e consolidando os dados do Mosaico...", spinner="clock"
    ):
        stations, _ = urlretrieve(ESTACOES, f"{folder}/estações.zip")
        pb, _ = urlretrieve(PLANO_BASICO, f"{folder}/canais.zip")
        estações = _read_estações(stations)
        plano_basico = _read_plano_basico(pb)
        df = estações.merge(plano_basico, on="Id", how="left")
        df.drop("Id", axis=1, inplace=True)
        df = clean_mosaico(folder, df)
        df.reset_index(drop=True, inplace=True)
        Path(stations).unlink()
        Path(pb).unlink()
        return save_df(df, folder, "mosaico")


def update_base(folder: Union[str, Path]) -> pd.DataFrame:
    """Wrapper que atualiza opcionalmente lê e atualiza as três bases indicadas anteriormente, as combina e salva o arquivo consolidado na folder `folder`"""
    stel = update_stel(folder).loc[:, TELECOM]
    radcom = update_radcom(folder).loc[:, SRD]
    mosaico = update_mosaico(folder).loc[:, RADIODIFUSAO]
    radcom["Num_Serviço"] = "231"
    radcom["Status"] = "RADCOM"
    radcom["Classe_Emissão"] = pd.NA
    radcom["Largura_Emissão"] = BW_MAP["231"]
    radcom["Entidade"] = radcom.Entidade.str.rstrip().str.lstrip()
    radcom["Num_Ato"] = pd.NA
    radcom["Data_Ato"] = pd.NA
    radcom["Validade_RF"] = pd.NA
    radcom["Fonte"] = "SRD"
    stel["Status"] = "L"
    stel["Num_Ato"] = pd.NA
    stel["Data_Ato"] = pd.NA
    stel["Entidade"] = stel.Entidade.str.rstrip().str.lstrip()
    stel["Fonte"] = "STEL"
    mosaico["Fonte"] = "MOS"
    mosaico["Classe_Emissão"] = pd.NA
    mosaico["Largura_Emissão"] = mosaico.Num_Serviço.map(BW_MAP)
    rd = (
        pd.concat([mosaico, radcom, stel])
        .sort_values(["Frequência", "Latitude", "Longitude"])
        .reset_index(drop=True)
    )
    rd = rd.drop_duplicates(keep="first").reset_index(drop=True)
    rd["BW(kHz)"] = rd.Largura_Emissão.apply(parse_bw)
    return save_df(rd, folder, "base")