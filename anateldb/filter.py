# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/filter.ipynb (unless otherwise specified).

__all__ = ['bump_version', 'get_modtimes', 'formatar_db']

# Cell
from pathlib import Path
import json
from datetime import datetime

import pandas as pd
from fastcore.test import *
from fastcore.script import call_parse, Param, store_true
from pyarrow import ArrowInvalid
from geopy.distance import geodesic
from rich.console import Console

from .constants import APP_ANALISE
from .read import read_base, read_aero
from .merge import merge_aero
from .format import df_optimize, optimize_objects

# Cell
def bump_version(version, part=2):
    version = version.split(".")
    version[part] = str(int(version[part]) + 1)
    for i in range(part + 1, 3):
        version[i] = "0"
    return ".".join(version)

# Cell
def get_modtimes(pasta):
    """
    Retorna a data de modificação dos arquivos de dados
    """
    # Pasta
    pasta = Path(pasta)
    if not pasta.is_dir():
        raise FileNotFoundError(f"Pasta {pasta} não encontrada")
    # Arquivos
    for suffix in [".parquet.gzip", ".fth", ".xlsx"]:
        if not (stel := pasta / f'stel{suffix}').is_file():
            raise FileNotFoundError(f"Arquivo {stel} não encontrado")
        if not (radcom := pasta / f'radcom{suffix}').is_file():
            raise FileNotFoundError(f"Arquivo {radcom} não encontrado")
        if not (mosaico := pasta / f'mosaico{suffix}').is_file():
            raise FileNotFoundError(f"Arquivo {mosaico} não encontrado")
        break
    if not (icao := pasta / 'icao.xlsx').is_file():  # ICAO
        raise FileNotFoundError(f"Arquivo {icao} não encontrado")
    if not (pmec := pasta / 'aisw.xlsx').is_file():  # PMEC
        raise FileNotFoundError(f"Arquivo {pmec} não encontrado")
    if not (geo := pasta / 'aisg.xlsx').is_file():  # GEO
        raise FileNotFoundError(f"Arquivo {geo} não encontrado")
    # Modificação
    mod_stel = datetime.fromtimestamp(stel.stat().st_mtime).strftime("%d/%m/%Y %H:%M:%S")
    mod_radcom = datetime.fromtimestamp(radcom.stat().st_mtime).strftime("%d/%m/%Y %H:%M:%S")
    mod_mosaico = datetime.fromtimestamp(mosaico.stat().st_mtime).strftime("%d/%m/%Y %H:%M:%S")
    mod_icao = pd.read_excel(icao, engine='openpyxl', sheet_name='ExtractDate').columns[0]
    mod_aisw = pd.read_excel(pmec, engine='openpyxl', sheet_name='ExtractDate').columns[0]
    mod_aisg = pd.read_excel(geo, engine='openpyxl', sheet_name='ExtractDate').columns[0]
    return {'STEL': mod_stel,
            'SRD': mod_radcom,
            'MOSAICO': mod_mosaico,
            'ICAO': mod_icao,
            'AISW': mod_aisw,
            'AISG': mod_aisg}

@call_parse
def formatar_db(
    path: Param("Pasta onde salvar os arquivos", str),
    up_base: Param("Atualizar as bases da Anatel", store_true) = False,
    up_icao: Param("Atualizar a base do ICAO", store_true) = False,
    up_pmec: Param("Atualizar a base do PMEC", store_true) = False,
    up_geo: Param("Atualizar a base do Geo", store_true) = False,
) -> None:
    dest = Path(path)
    dest.mkdir(parents=True, exist_ok=True)
    console = Console()
    console.print(":scroll:[green]Lendo as bases de dados da Anatel...")
    rd = read_base(path, up_base)
    rd["Descrição"] = (
        "["
        + rd.Fonte.astype("string")
        + "] "
        + rd.Status.astype("string").fillna("-")
        + ", "
        + rd.Entidade.astype("string").fillna("-").str.title()
        + " ("
        + rd.Fistel.astype("string").fillna("-")
        + ", "
        + rd["Número_Estação"].astype("string").fillna("-")
        + "), "
        + rd.Município.astype("string").fillna("-")
        + "/"
        + rd.UF.astype("string").fillna("-")
    )


    export_columns = [
        "Frequência",
        "Latitude",
        "Longitude",
        "Descrição",
        "Num_Serviço",
        "Número_Estação",
        "Classe_Emissão",
        "BW(kHz)",
    ]
    rd = rd.loc[:, export_columns]
    rd.columns = APP_ANALISE
    common, new = read_aero(path, up_icao, up_pmec, up_geo)
    rd = merge_aero(rd, common, new)
    rd['Frequency'] = rd['Frequency'].astype('float')
    console.print(":card_file_box:[green]Salvando os arquivos...")
    d = json.loads((dest / "VersionFile.json").read_text())
    mod_times = get_modtimes(path)
    mod_times['ReleaseDate'] = datetime.today().strftime("%d/%m/%Y %H:%M:%S")
    for c in ['Latitude', 'Longitude']:
        rd.loc[:, c] = rd.loc[:, c].fillna(-1).astype('float64')
    rd['BW'] = rd['BW'].fillna(-1).astype('float32')
    rd['Service'] = rd.Service.fillna('-1').astype('category')
    rd['Station'] = rd.Station.fillna('-1').astype('string')
    rd = optimize_objects(rd, [])
    rd = rd.drop_duplicates(keep="first").reset_index(drop=True)
    rd.sort_values(by=['Frequency', 'Latitude', 'Longitude'], inplace=True)
    rd['Id'] = rd.index.to_numpy()
    rd.to_parquet(f"{dest}/AnatelDB.parquet.gzip", compression='gzip', index=False)
    rd.to_excel(f'{dest}/AnatelDB.xlsx', index=False, engine='openpyxl', sheet_name='DataBase')
    d["anateldb"]["Version"] = bump_version(d["anateldb"]["Version"])
    d['anateldb'].update(mod_times)
    json.dump(d, (dest / "VersionFile.json").open("w"))
    Path(dest / ".version").write_text(f"v{d['anateldb']['Version']}")
    console.print("Sucesso :zap:")
    return rd