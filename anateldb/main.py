# AUTOGENERATED! DO NOT EDIT! File to edit: ..\nbs\main.ipynb.

# %% auto 0
__all__ = ['bump_version', 'get_modtimes', 'check_modify_row', 'add_aero', 'get_db']

# %% ..\nbs\main.ipynb 2
from pathlib import Path
import json
from typing import Union
from datetime import datetime
from tqdm.auto import tqdm

import pandas as pd
from fastcore.test import *
from fastcore.script import call_parse, Param, store_true
from pyarrow import ArrowInvalid
from geopy.distance import geodesic
from rich import print

from .constants import APP_ANALISE
from .reading import read_base, read_aero
from .merging import merge_aero
from .format import df_optimize, optimize_objects
from .merging import get_subsets, check_add_row, product, MAX_DIST

# %% ..\nbs\main.ipynb 3
def bump_version(version, part=2):
    version = version.split(".")
    version[part] = str(int(version[part]) + 1)
    for i in range(part + 1, 3):
        version[i] = "0"
    return ".".join(version)

# %% ..\nbs\main.ipynb 4
def get_modtimes(pasta):
    """
    Retorna a data de modificação dos arquivos de dados
    """
    # Pasta
    pasta = Path(pasta)
    if not pasta.is_dir():
        raise FileNotFoundError(f"Pasta {pasta} não encontrada")
    # Arquivos
    for suffix in [".parquet.gzip", ".fth", ".xlsx"]:
        if not (stel := pasta / f'stel{suffix}').is_file():
            raise FileNotFoundError(f"Arquivo {stel} não encontrado")
        if not (radcom := pasta / f'radcom{suffix}').is_file():
            raise FileNotFoundError(f"Arquivo {radcom} não encontrado")
        if not (mosaico := pasta / f'mosaico{suffix}').is_file():
            raise FileNotFoundError(f"Arquivo {mosaico} não encontrado")
        break
    if not (icao := pasta / 'icao.xlsx').is_file():  # ICAO
        raise FileNotFoundError(f"Arquivo {icao} não encontrado")
    if not (pmec := pasta / 'aisw.xlsx').is_file():  # PMEC
        raise FileNotFoundError(f"Arquivo {pmec} não encontrado")
    if not (geo := pasta / 'aisg.xlsx').is_file():  # GEO
        raise FileNotFoundError(f"Arquivo {geo} não encontrado")
    # Modificação
    mod_stel = datetime.fromtimestamp(stel.stat().st_mtime).strftime("%d/%m/%Y %H:%M:%S")
    mod_radcom = datetime.fromtimestamp(radcom.stat().st_mtime).strftime("%d/%m/%Y %H:%M:%S")
    mod_mosaico = datetime.fromtimestamp(mosaico.stat().st_mtime).strftime("%d/%m/%Y %H:%M:%S")
    mod_icao = pd.read_excel(icao, engine='openpyxl', sheet_name='ExtractDate').columns[0]
    mod_aisw = pd.read_excel(pmec, engine='openpyxl', sheet_name='ExtractDate').columns[0]
    mod_aisg = pd.read_excel(geo, engine='openpyxl', sheet_name='ExtractDate').columns[0]
    return {'STEL': mod_stel,
            'SRD': mod_radcom,
            'MOSAICO': mod_mosaico,
            'ICAO': mod_icao,
            'AISW': mod_aisw,
            'AISG': mod_aisg}


# %% ..\nbs\main.ipynb 5
def check_modify_row(df, # DataFrame para mesclar adicionar o registro
                  f, # Frequência (MHz) em análise do registro 
                  rows, # Lista de registros para mesclar
                  dicts, # Dicionário fonte dos registros
):
    """Mescla os registros em `rows` de frequência `f` e os adiciona como uma linha do DataFrame `df`
    Os registros em `rows` somente são mesclados se ainda constarem nos dicionários fonte `dicts`
    Após a mesclagem, os registros são removidos dos dicionários fonte `dicts`   
    """
    if all(row.Index in dict for row, dict in zip(rows, dicts)):
        lat = sum(row.Latitude for row in rows) / len(rows)
        long = sum(row.Longitude for row in rows) / len(rows)
        desc = ' | '.join(row.Description for row in rows)
        d = {'Frequency': f, 'Latitude': lat, 'Longitude': long, 'Description': desc}
        for row, dict in zip(rows, dicts):
            dict.pop(row.Index)
        for k,v in d.items():
            df.loc[row.Index, k] = v
    return df

# %% ..\nbs\main.ipynb 6
def add_aero(base, # Base Consolidada Anatel
             aero, # Base da Aeronáutica
):
    """Mescla os registros de frequência em comum da base da Aeronáutica com a base da Anatel
    Os registros são mesclados se a distância entre eles for menor que `MAX_DIST`
    do contrário são adicionados individualmente como uma linha na base da Anatel`	
    """
    frequencies = set(base.Frequency.unique()).intersection(aero.Frequency.unique())
    for f in tqdm(frequencies):
        sa, sb = get_subsets(f, base, aero)
        if all([sa, sb]): # Somente há registros para mesclar se estiverem nos dois conjuntos
            for fa, fb in product(sa.copy().values(), sb.copy().values()):
                if geodesic((fa.Latitude, fa.Longitude), (fb.Latitude, fb.Longitude)).km <= MAX_DIST:
                    base = check_modify_row(base, f, [fa, fb], [sa, sb]) 
        for r in sb.copy().values():# Do contrário os registros são adicionados individualmente ao DataFrame
            base = check_add_row(base, f, [r], [sb])
    return base

# %% ..\nbs\main.ipynb 7
def get_db(
    path: Union[str, Path], # Pasta onde salvar os arquivos",
    up_base: bool=False, # Atualizar as bases da Anatel?
    up_icao: bool=False, # Atualizar a base do ICAO?
    up_pmec: bool=False, # Atualizar a base do AISWEB?
    up_geo: bool=False, # Atualizar a base do GeoAISWEB?
) -> None:
    """Lê e opcionalmente atualiza as bases da Anatel, mescla as bases da Aeronáutica e salva os arquivos"""
    dest = Path(path)
    dest.mkdir(parents=True, exist_ok=True)
    print(":scroll:[green]Lendo as bases de dados da Anatel...")
    rd = read_base(path, up_base)
    rd["Descrição"] = (
        "["
        + rd.Fonte.astype("string").fillna("NI")
        + "] "
        + rd.Status.astype("string").fillna("NI")
        + ", "
        + rd.Classe.astype("string").fillna("NI")
        + ", "
        + rd.Entidade.astype("string").fillna("NI").str.title()
        + " ("
        + rd.Fistel.astype("string").fillna("NI")
        + ", "
        + rd["Número_Estação"].astype("string").fillna("NI")
        + "), "
        + rd.Município.astype("string").fillna("NI")
        + "/"
        + rd.UF.astype("string").fillna("NI")
    )


    export_columns = [
        "Frequência",
        "Latitude",
        "Longitude",
        "Descrição",
        "Num_Serviço",
        "Número_Estação",
        "Classe_Emissão",
        "BW(kHz)",
    ]
    rd = rd.loc[:, export_columns]
    rd.columns = APP_ANALISE
    print(":airplane:[blue]Adicionando os registros da Aeronáutica.")
    aero = read_aero(path)
    rd = add_aero(rd, aero)
    print(":card_file_box:[green]Salvando os arquivos...")
    d = json.loads((dest / "VersionFile.json").read_text())
    mod_times = get_modtimes(path)
    mod_times['ReleaseDate'] = datetime.today().strftime("%d/%m/%Y %H:%M:%S")
    for c in ['Latitude', 'Longitude']:
        rd.loc[:, c] = rd.loc[:, c].fillna(-1).astype('float32')

    rd['Frequency'] = rd['Frequency'].astype('category')
    rd['Description'] = rd['Description'].astype('string').fillna('NI')
    rd['Service'] = rd.Service.astype('float').fillna(-1).astype('int16')
    rd['Station'] = rd.Station.astype('float').fillna(-1).astype('int32') # Fix this
    rd['BW'] = rd['BW'].astype('float32').fillna(-1)
    rd['Class'] = rd.Class.astype('string').fillna('NI').astype('category')
    rd = rd.drop_duplicates(keep="first").reset_index(drop=True)
    rd.sort_values(by=['Frequency', 'Latitude', 'Longitude'], inplace=True)
    rd['Id'] = [f'#{i}' for i in rd.index]
    rd['Id'] = rd.Id.astype('string')
    rd = rd.loc[:, ['Id', 'Frequency', 'Latitude', 'Longitude', 'Description', 'Service', 'Station', 'Class', 'BW']]
    rd.to_parquet(f"{dest}/AnatelDB.parquet.gzip", compression='gzip', index=False)
    d["anateldb"]["Version"] = bump_version(d["anateldb"]["Version"])
    d['anateldb'].update(mod_times)
    json.dump(d, (dest / "VersionFile.json").open("w"))
    Path(dest / ".version").write_text(f"v{d['anateldb']['Version']}")
    print("Sucesso :zap:")
    return rd
